{\rtf1\ansi\ansicpg1252\uc1\deff0
{\fonttbl{\f0\fmodern\fcharset0\fprq2 CourierNewPSMT;}}
{\colortbl;\red0\green0\blue0;\red255\green255\blue255;}
\paperw12240\paperh15840\margl1800\margr1800\margt1440\margb1440\fet2\ftnbj\aenddoc
\pgnrestart\pgnstarts0
\pard\plain \ri-10862\ltrch\loch {\f0\fs24\b0\i0 Never before, data were so ubiquitous. Never before, a managed access to external, non-native data has been so easy. Unfortunately, *using* that same external, non-native data shows extremely difficult: For a data consuming application, interpreting and using external data requires re-engineering your software to transform that data to fit the model your software applies. }{\field{\*\fldinst HYPERLINK "scrivcmt://B6DB7C40-0A3A-4B07-B480-99F0BFEF013F"}{\fldrslt\f0\fs24\b0\i0 For instance}}{\f0\fs24\b0\i0 , }
\par\plain \f0\fs24\b0\i0
\par\plain {\f0\fs24\b0\i0 This semantic part of interoperability represents a bleeding edge in software development. Its most disconcerting consequences are flat interoperability failures, or seemingly correct but quite invalid data analysis with devastating system behaviour as result. Their correction to valid semantic interoperability (SIOp) always requires a significant time and effort that shows a substantial impediment towards business operations and agility, the next glass ceiling for ICT. This is because current SIOp implementations are essentially based on establishing a convention on the semantics of the terms that are used during the collaboration. Arriving at such conventions, i.e., developing a semantic standard, consumes a very long time that is measured in months at least. Moreover, such convention can be considered a semantic monolith, which makes dealing with external (outside the monolith) data impossible, unless again a time consuming semantic adoption process is initiated. Moreover, with their strong tendency to rely on shared and unified semantics, semantic standards consider semantic heterogeneity a bug as opposed to a feature that is required to achieve semantic accuracy. Nevertheless, this conventions-based approach towards SIOp is accepted folklore in ICT. Due to the large uptake of the Internet, the Internet of Things (IoT), cloud computing and big data, and driven by economical pressure to intensify enterprise collaboration, we consider such approach "too little, too late". Instead, a definitive SIOp capability requires an approach that aims at an *access-and-play* SIOp potential by moving the majority of the effort to achieve SIOp out of the critical path, from redesign time \loch\af0\hich\af0\dbch\af0\uc1\u8220\'93after the fact\u8221\'94 to preparatory design time, viz. design to collaborate. In this way, software systems, applications or software components -- henceforth collectively denoted as software agents -- can realise collaboration in due time, when faced, at some point in their life cycle, with the need to exchange data with other however *unanticipated* software agents outside the semantic monolith. Business agility emerges once you only have to access and play, namely (i) to achieve SIOp in due time, (ii) with data that are generated outside the own semantic monolith.}
\par\plain \f0\fs24\b0\i0
\par\plain {\f0\fs24\b0\i0 Access-and-play SIOp demands a notion on semantics, often denoted in layman\loch\af0\hich\af0\dbch\af0\uc1\u8217\'92s terms as the \u8220\'93understanding of the data\u8221\'94. Despite the used terms *smart* or *intelligent*, e.g., smart watches, or intelligent autonomous systems, computers are inherently stupid. The notion of understanding is completely alien to them. In fact, it is the IT engineer who performs the understanding of data upfront, and implements the proper response to such understanding in program code. The major impediments to the automation for access-and-play SIOp is laid in the nature of semantics itself: The meaning of a term ultimately relates to what it denotes in reality, the so-called term grounding, whilst this relation cannot be deferred from the shape, structure or other characteristics of term itself due to its total arbitrariness. When we acknowledge this semiotic explanation on semantics (on which we elaborate in the next Section), we are confronted with the inevitable separation between languages (software code, modelling languages and natural languages alike) and reality (entities, e.g., things, events and properties of things), also known as the *grounding problem*. In information systems, addressing this fundamental distinction is at best extremely narrow [@Steels:2008tr], or not present at all [@Cregan2007]. Despite the progress of artificial intelligence (AI), its capability to build some form of conscience and gain even a beginning of an understanding to relate a term to what it denotes in reality, also known as "strong AI", does not yet exist and is expected to emerge on the long term only, if ever [@XiuquanLi2017]. Its counterpart "weak AI" with its otherwise highly relevant and important achievements in reasoning, prediction and analysis, is based on machinery that relies on language only and can therefore never make the step to reality on its own [@Scheider:2012tj]. Still, it\u8217\'92s all we\u8217\'92ve got at this very moment and we\u8217\'92ll have to make do with it for the time being in order to achieve semantics and SIOp. We therefore cannot neglect the existence of the grounding problem and its semiotic origins. Nevertheless, we do. For instance, when we are asked to explain how we address the grounding problem in the design of our software agent, we can\u8217\'92t; when we are asked to point at the semantics parts in the code of our software agent, we can't. The same question however about, e.g., its scalability, will render a lecture with adequate references to the underlying architecture. We thus remain at a loss of how to engineer semantics into software agents. However, without a clear understanding on semantics and its contribution to the software agent, we are lacking the bridgehead within the software agent that is fundamental to the semantic interoperability bridge. Hence, the first architectural concern to consider is the nature of semantics in software, and we will address that in the next section. }
\par\plain \f0\fs24\b0\i0
\par\plain \f0\fs24\b0\i0
\par\plain {\f0\fs24\b0\i0 Our contributions include:}
\par\plain \f0\fs24\b0\i0
\par\plain {\f0\fs24\b0\i0 * }
\par\plain \f0\fs24\b0\i0
\par\plain \f0\fs24\b0\i0
\par\plain \f0\fs24\b0\i0
\par\plain \f0\fs24\b0\i0
\par\plain \f0\fs24\b0\i0
\par\plain {\f0\fs24\b0\i0 ----}
\par\plain \f0\fs24\b0\i0
\par\plain {\f0\fs24\b0\i0 Although technologies such as the Semantic Web and ontologies are available, and despite the principles and practises of the model driven architecture paradigm, no architectural guidance to semantic interoperability exists, neither in terms of architectural principles nor as design practises.}
\par\plain \f0\fs24\b0\i0
\par\plain {\f0\fs24\b0\i0 Semantics and semantic interoperability (SIOp) can be considered the next glass ceiling for IT. }
\par\plain \f0\fs24\b0\i0
\par\plain {\f0\fs24\b0\i0 Given the exponential growth in semantic heterogeneity that follows from distributed use of distributed supplied services over distributed resources, information systems are in a desperate need for a managed semantics, which, similar to the principle to store data only once in order to prevent data conflicts, controls the semantic heterogeneity from a central location in your architecture. to an automated SIOp capability to break through this ceiling. information systems are in a desperate need for an automated SIOp capability to break through this ceiling.}
\par\plain \f0\fs24\b0\i0
\par\plain \f0\fs24\b0\i0
\par\plain \f0\fs24\b0\i0
\par\pard\plain \ltrch\loch \f0\fs24\b0\i0}