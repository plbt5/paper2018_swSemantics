{\rtf1\ansi\ansicpg1252\uc1\deff0
{\fonttbl{\f0\fmodern\fcharset0\fprq2 CourierNewPSMT;}}
{\colortbl;\red0\green0\blue0;\red255\green255\blue255;}
\paperw12240\paperh15840\margl1800\margr1800\margt1440\margb1440\fet2\ftnbj\aenddoc
\pgnrestart\pgnstarts0
\pard\plain \ltrch\loch {\f0\fs24\b0\i0 \line \line }
\par\plain {\f0\fs24\b0\i0 \line \line }
\par\plain {\f0\fs24\b0\i0 Concerning the grounding problem, since strong AI does not yet exists, and weak AI is not strong enough, the only tool to ground the terms from which semantics can emerge, therefore, remains the human brain that complements the shortcomings of weak AI. And that is exactly the current state of the art in software engineering: being aware of the application domain during design-time, the software engineer provides for the necessary semantics and assures, by means of their encoding in software constraints, schemata, class definitions and matching business and domain rules, that the particular software agent operates on the data in a way that is isomorphic to the reality the software agent is about. Although this may solve the grounding problem for the agent's native data, it does so by sacrificing the software agent's flexibility to process foreign data that commits to another grounding, a flexibility that is the essential condition to sIOP in general, and even more so for access-and-play sIOP. This would call for another solution to the grounding problem, but as just explained, we're "stuck" with weak AI that cannot resolve it differently. When we accept this implicit semantic rigidness of software agents, the question then becomes whether we can deal with the semantic rigidness in another way? Because one cannot deal with tacit knowledge, the assumption underlying the question is that semantics can be made explicit. Fortunately, the Semantic Web (SW) initiative at the one hand [@W3C2015], and the ontology engineering movement on the other [@IAOA2013], stimulate such explicit attention for semantics. We therefore can focus on the issue of semantic rigidness, and consider this question, and particularly its relationship with the SW and ontology technologies, as a software engineering issue that, by its generic nature, should be resolved at the level of architecture.\line \line }
\par\plain {\f0\fs24\b0\i0 \line }
\par\plain {\f0\fs24\b0\i0 * Contemporary solutions are investigated along three different reconciliation techniques [@Silva2007, @Hameed2004]: merging, alignment [@Balachandar2013, @Taye2010] and integration. The merging and integration techniques are characterized by their producing a new, unified world view from the existing ones. In contrast, the alignment technique brings the different views "(...) into mutual agreement, making them consistent and coherent" [@Hameed2004]. From an architectural point of view, the alignment technique brings about a significant higher form of *loose coupling* than the other two techniques. That is the precise reason why we defend to found sIOP on the former one and reject the latter techniques. Furthermore, although any design time reconciliation technique is contrasting with the *access-and-play* capability that we imply when we speak about sIOP, by introducing alignments, progress towards access-and-play is still being made: (i) required modifications are lifted from the implementation level to the configuration level; (ii) sIOP functionality can be abstracted and collected into a distinct component for reuse; (iii) designing and developing semantic mappings becomes a distinct and domain-independent engineering discipline with dedicated research, tooling and artifacts, and, finally, (iv) reconciliation has been recognized as a plausible solution for a long time [@Euzenat:2013ie]. What remains open, however, is its architectural perspective, notably about agreeing on the concerns that are pursued and the principles for their underpinning, the services that result, the standards that such services would require and the available initiatives that represent potential candidate standards. An architecture for sIOP should be designed to consolidate related architectural concerns about data re-use and independent application development for collaborating software agents, bringing secondary benefits on concerns about semantic maintainability and modifiability. Certainly, the semantic web initiative at the one hand [@W3C2015], and the ontology engineering movement on the other [@IAOA2013], stimulate explicit attention for semantics. Still, in order for (legacy) applications to respond, in ever decreasing time-spans, to ever increasing demands for collaboration, those explicit semantics need (i) to be brought into coherence with (extra-)functional aspects of the system and its components, (ii) to align with all data models and data representations as they occur in their many different forms in distributed systems, and (iii) to become synchronized with the system life cycle. In other words, semantics require to become properly and explicitly embedded into the architectures of the underlying systems and components. Only then we can claim to have coped with the semantic reminiscences of the monolithic beast and provide for semantic interoperability on an *access-and-play* bases.\line \line }
\par\plain {\f0\fs24\b0\i0 > Dan de onderstaande teksten lezen, bekijken welke nieuwe probleemaspecten ze identificeren, en een korte samenvatting van elk geven als apart blokje \line \line }
\par\plain {\f0\fs24\b0\i0 >Finally, insert overview of article, where possible combined for each section with shortcomings of related work.\line \line \line }
\par\plain {\f0\fs24\b0\i0 ----\line \line }
\par\plain {\f0\fs24\b0\i0 The grounding problem in itself has another consequence in relation to the distributed nature of sIOP that we explain as follows. In essence, data are *encodings* about the state of affairs in that part of reality that the software is interested about. With the absence of strong AI, only the software agent that generated the data (or more precisely, the software engineer that produced the software agent) possesses the know-how to "decode" the data, i.e., to connect the signifier with what is signified in reality. The realm of that know-how, denoted here as *background knowledge*, represents the semantic monolith, and it is being demarcated in design time: any software agent that, through its software engineer, is made aware of that background knowledge, through bilateral agreements, domain-specific standards or other conventions, has implemented measures to apply the data in accordance to what they refer to in reality. In conclusion, sIOP cannot exist without sharing the background knowledge that relates the used signifiers (tokens) with what is signified in reality. \line And here we hit the concrete wall of infinite regress, depicted in Figure 2, since communicating background knowledge is equivalent to communicating data: we communicate bare tokens, the decoding of which requires background knowledge itself. It is this infinite regress that makes it impossible to communicate the relation between the signifers (tokens) and the signifed in reality. Ipso facto, where semantics cannot be communicated, semantic interoperability cannot emerge, hence the semantic gap.\line \line \line }
\par\plain {\f0\fs24\b0\i0 Where and when to position her is a question of architecture: to balance, e.g., the complementing capabilities and shortcomings of man and machine, and particularly to complement the shortcomings of weak AI with human's strong AI; or functionality that should coagulate into software code versus required adaptivity by human-assisted configurations, or maximizing reuse of weak AI artifacts and minimizing deployment delays, to name a few.\line \line \line \line }
\par\plain {\f0\fs24\b0\i0 focus on the next best that we *can* influence, being the *ontological commitment*. What we mean with this is the following: When we use a term, and particularly a term from the highest level of abstraction of our (modelling) language, to what *category* of things (or relations) in reality do we refer, i.e., what things in reality do we commit to when using those abstract terms from which all other elements in our model originate. Indeed, to achieve sIOP we side step the grounding problem and apply the ontological commitment in a function of *semantic convention*. This suggests that ontological commitment is absent in contemporary software models. A characteristic of ontological commitment, however, is that its absence is impossible; on introducing a concept, i.e., an element in a (software) model which stands for a particular category of entities (or relations between them) in reality, there always exists background knowledge on the characteristics of that category. For instance, what individuals are considered part of it and how these individuals relate to other categories, or what other categories are contained within it. Such background knowledge, consciously or not, represents the ontological commitment of that concept when it impacts on how the concept plays along with the other elements in the model and, eventually, how individuals that belong to that concept, i.e., data, are being processed by the software. We do not suggest that ontological commitment is absent, but claim that the *explication* of the ontological commitment is either absent, and/or the number of concepts that carry an ontological commitment is *extremely small* in contemporary modeling languages. In other words, every model assumes an underlying ontological commitment; by keeping this implicit, no matter how thoroughly designed the model has been, its underlying ontological commitment is non-existent for the collaborating peer, which clearly ruins sIOP. Acknowledging its significance to sIOP and the architectural concerns that the ontological commitment addresses, the roles it plays, its position within and contributions to other artifacts in the architectural realm, these are necessary criteria to be included in architecture paradigms that claim to support sIOP. To the best of our knowledge, none of the contemporary architectural paradigms, be it view-based models such as Kruchten, IEEE1471-2000, the Zachman Framework [@Zachman1987], RM-ODP [@Linington1995], TOGAF [TBD], DoDAF [TBD], and RASDS-E [TBD] alike, or model-driven architectures that follow from the OMG [TBD] reference architectures, acknowledge the significance of ontological commitment for sIOP and provide for guidelines on how to go about it. \line \line }
\par\plain {\f0\fs24\b0\i0 This publication presents architectural cornerstones for a highly needed access-and-play sIOP capability. To that end, we discuss the necessity for a human-in-the-loop approach, its contradiction with the access-and-play sIOP capability, and describe how these conflicting sIOP concerns can be architecturally balanced. Furthermore, we discuss the need to acknowledge ontological commitment and provide for suggestions to its integration in view-based and model-driven architectural paradigms. \line \line }
\par\plain {\f0\fs24\b0\i0 >Insert overview of article, where possible combined for each section with shortcomings of related work.\line \line }
\par\plain {\f0\fs24\b0\i0 ----------\line \line }
\par\plain {\f0\fs24\b0\i0 Earlier monolithic aspects of software have always been "abstracted away". Abstracting from the application code the particulars of the (extra-)functional asset at hand is done by extracting them into a distinct component that can provision the necessary (extra-)functional services outside the monolith. Then, by assuring that these services can be accessed through a *standardized interface*, any application can make use of its (extra-)functional assets, with which the monolithic characteristic was effectively removed. Regarding sIOP, then, the task would be to abstract the particular data semantics from their original application in order to enable re-use of that data outside their original monolithic application. Such approach assumes that agreement can be reached on the subject at hand, which, for many if not all previous monolithic aspects of (hardware and) software hold indeed: the system engineering community had to agree on *how* the abstraction was to take place, as opposed to *what* was being abstracted. Unfortunately, in case of semantics, the debate is primarily on *what* aspect of reality is being abstracted. This comes very close, or is even identical, to a discussion that continues already since Socrates (around 350 BC); philosophers try to understand the metaphysical and physical universe including humans and their world. Without claiming a philosophical origin *per se*, semantic inconsistencies remain widespread, in semantic standards, vocabularies or other conventions about the meaning that should be given to syntax and structure [@Guarino1994a]. More often than not, these inconsistencies are manifestations of our individual background knowledge, believes, cultural entail, and perspectives that led to certain linguistic use. In short, we take the stance that semantic heterogeneity should *not* be considered a bug to be corrected by insisting on one single truth, but a feature that should be exploited to express ourselves as accurately as possible. This sharply contrasts with our departure that we only consider \loch\af0\hich\af0\dbch\af0\uc1\u8220\'93weak AI\u8221\'94, which assumes that the capability of software towards \u8220\'93understanding\u8221\'94 is limited to comparing syntax and following logical rules, only. This contradiction is the first question that we investigate, and to its resolution we present in Section 2 background material on what signifies semantics and the role of semiotics, and set the baseline for this paper by providing for our interpretation on semantics *in* and semantic interoperablity *between* software agents.\line \line }
\par\plain {\f0\fs24\b0\i0 Literature clarifies that "weak AI" is not capable to resolve semantic heterogeneity at run time, while its counterpart "strong AI" does not yet exist and is expected to emerge in long term only, if ever [@XiuquanLi2017]. Therefore, if we want to bridge the semantic gap at run time, we must prepare such capability at design time and introduce a human in the loop to reconcile the different world views of collaborating software agents. However, design time reconciliation is contrasting with the *access-and-play* capability that we imply when we speak about sIOP. \line \line \line \line }
\par\plain {\f0\fs24\b0\i0 This contradiction is the second issue that we address, and in Chapter 3 we take a principled approach and investigate the primary concerns that are pursued with an architecture for sIOP and the principles for its underpinning. This gives the necessary foundation for analyzing the optimal balance between design time capabilities for reconciliation and maximizing the run time progress towards the access-and-play demands.\line \line }
\par\plain {\f0\fs24\b0\i0 the services that result, the standards that such services would require and the available initiatives that represent potential candidate standards. An architecture for sIOP should be designed to consolidate related architectural concerns about data re-use and independent application development for collaborating software agents, bringing secondary benefits on concerns about semantic maintainability and modifiability. . \line \line }
\par\plain {\f0\fs24\b0\i0 an explicit check and balances between \line \line \line \line }
\par\plain {\f0\fs24\b0\i0 In this paper we discuss the architectural implications for a definitive sIOP capability in support of such access-and-play potential for software agents, which at some point in their life cycle will be faced with the need to exchange data with other (however unanticipated) software agents. A major concern for semantic interoperability is then to balance between at least three conflicting demands. Firstly, to be able to express oneself as accurately as necessary (but not more), i.e., to adopt a language that is sufficiently adequate to represent the notions that we are interested in but neither less nor more. Secondly, to become independent, to the greatest extent possible, from the syntax that is used to represent semantics, i.e., to remain free from representational conventions. Thirdly, to exchange data between collaborating software agents such that the state of affairs the data refer to, remains the same, i.e., "that data elements are understood in the same way by communicating parties" (extract from EIRA). \line We elaborate on the consequences of this and similar concerns that we consider the fundamental sIOP concerns in Section 3. We also find (i) that these concerns are not addressed by any of the contemporary, view-based architectural models, i.e., Kruchten, IEEE1471-2000, the Zachman Framework [@Zachman1987], RM-ODP [@Linington1995], TOGAF [TBD], DoDAF [TBD], and RASDS-E [TBD] alike; (ii) that a similar situation holds for the model-based architectural paradigm (MDA/MDE), albeit in a more subtle way that involves philsophy and refers to the relationship with reality; (iii) that generic interoperability (IOP) is already widely acknowledged as an architectural concern by, e.g., software quality models (ISO SQuaRE [TBD] and ISO-9126 extended [@Zeist1996]), as major quality attributes (and related tactics) by [TBD software engineering institute] and [@Bass2013]; (iv) that in order to reach IOP, semantics are identified as its a cornerstone however propose as tactics to manage the interfaces, only, implying some notion of mutual agreement; and (v) that although specific IOP frameworks, such as the EIF and EIRA from the EC, indeed identify a semantic viewpoint, most of the solutions are however based on mutual agreement, usually in the form of standards. These findings, together with our stance to embrace semantic heterogeneity, justify the demand for an explicit and more formal approach towards semantics and sIOP in contemporary architectural paradigms. \line \line }
\par\plain {\f0\fs24\b0\i0 We observe that concerns result in basic architectural pattern, and therefore apply concerns on sIOP as main foundation to our work. To that end, we gather in Section 4 these concerns and investigate about the architectural principles that are foundational to the provisioning of a sIOP capability in software agents. We conclude that for the large part it is necessary to provide for *loose coupling* at the semantic level, i.e., become, to the greatest extend possible, independent from how semantics have been expressed in syntax by the collaborating peer. In Section 5 we show how these sIOP principles can be consolidated, first as an additional architectural view and viewpoint for view-based architectures, and in a semantic model with semantic components for model-based architectures. Finally, in Section 6 we evaluate our theory on architectural considerations for the consolidation of semantic interoperablity by its implementation in [a desk mockup/ working prototype]. In Section 7 we discuss the results achieved by the work in Section 5, and arrive at the final conclusion that the explicit architectural support for semantic interoperability is a necessary element for the evolution of IT. But first we will present our interpretation on semantics in software, and semantic interoperablity between software components.\line \line }
\par\plain {\f0\fs24\b0\i0 > In addition to the architecture fwk you mention, you might also consider specific IOP frameworks, such as the EIF and EIRA from the EC, which is also architecture centric. IOP is addressed from 4 viewpoints: technical, semantics, organisational and legal. Semantic interoperability is defined as "enables organisations to process information from external sources in a meaningful manner. It ensures that the precise meaning of exchanged information is understood and preserved throughout exchanges between parties.\line In the context of the EIF, semantic interoperability encompasses the following aspects: \line \bullet Semantic interoperability is about the meaning of data elements and the relationship between them. It includes developing vocabulary to describe data exchanges, and ensures that data elements are understood in the same way by communicating parties. \line \bullet Syntactic interoperability is about describing the exact format of the information to be exchanged in terms of grammar, format and schemas. " (extract from EIRA)\line Most of the solutions are however based on mutual agreement, usually in the form of standards. \line \line \line }
\par\plain {\f0\fs24\b0\i0 > "... perhaps a more productive definition on the Semantic Web is to describe semantic interoperability in terms of shared inferences. " \line > The following sections are in a provisional stage only. I will continue on these ...\line \line }
\par\plain {\f0\fs24\b0\i0 [^1] Semiotics: the study of signs and symbols as a significant part of communications. As different from linguistics, however, semiotics also studies non-linguistic sign systems.}}